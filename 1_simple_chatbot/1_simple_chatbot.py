# –¢–µ—Ä–º–∏–Ω–∞–ª VSCODE:
#(base) D:\ollama_chatbot>conda activate conda_env_rae
#(conda_env_rae) D:\ollama_chatbot>ollama list
#(conda_env_rae) D:\ollama_chatbot>ollama run llama3.2:latest
#(conda_env_rae) D:\ollama_chatbot>ollama
# –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª 1_simple_chatbot.py
#(conda_env_rae) D:\ollama_chatbot>pip install langchain
#(conda_env_rae) D:\ollama_chatbot>pip install -qU langchain-ollama 
#(conda_env_rae) D:\ollama_chatbot>pip install streamlit 

# –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–¥:
# (conda_env_rae) D:\ollama_chatbot\1_simple_chatbot>streamlit run 1_simple_chatbot.py

import streamlit as st
from langchain_ollama import ChatOllama

if "chat_history" not in st.session_state:
    st.session_state['chat_history'] = []


st.title("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: —á–∞—Ç-–±–æ—Ç, –¥–∞—é—â–∏–π –æ—Ç–≤–µ—Ç –±–µ–∑ —É—á–µ—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å –Ω–∏–º –æ–±—â–µ–Ω–∏—è")
with st.form("llm-form"):
    question_text = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å")
    submit = st.form_submit_button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å")

def generate_answer(question_text):
    base_url = "http://localhost:11434/"
    model_name = "llama3.2:latest"
    model = ChatOllama(model= model_name, base_url=base_url)
    answer = model.invoke(question_text)
    return answer.content

if question_text and submit:
    with st.spinner("–í–æ–ø—Ä–æ—Å –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ..."):
        answer = generate_answer(question_text)
        st.session_state['chat_history'].append({"user": question_text, "ollama": answer})
        st.write(answer)

st.write("## –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞")
for chat in reversed(st.session_state['chat_history']):
    st.write(f"**üßë –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**: {chat['user']}")
    st.write(f"**üß† –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞**: {chat['ollama']}")
    st.write("---")